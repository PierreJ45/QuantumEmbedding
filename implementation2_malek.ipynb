{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    CrossEntropyLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "n_samples = 100 # dataset size (train)\n",
    "\n",
    "num_inputs = 2 # num of features (n)\n",
    "num_params = 12 # num of parameters (m)\n",
    "num_qubits = 2 # num of qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST train data\n",
    "X_train = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Filter out labels to keep only labels 0 and 1\n",
    "idx = np.append(\n",
    "    np.where(X_train.targets == 0)[0][:n_samples],\n",
    "    np.where(X_train.targets == 1)[0][:n_samples]\n",
    ")\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qcc(num_qubits, num_inputs, num_params):\n",
    "\n",
    "  inputs = [Parameter(f\"x{i}\") for i in range(1, num_inputs+1)] \n",
    "  params = [Parameter(f\"theta{i}\") for i in range(1, num_params+1)]\n",
    "\n",
    "  qcc = QuantumCircuit(num_qubits) \n",
    "\n",
    "  x1 = inputs[0]\n",
    "  x2 = inputs[1]\n",
    "  theta1 = params[0]\n",
    "  theta2 = params[1]\n",
    "  theta3 = params[2]\n",
    "  theta4 = params[3]\n",
    "  theta5 = params[4]\n",
    "  theta6 = params[5]\n",
    "  theta7 = params[6]\n",
    "  theta8 = params[7]\n",
    "  theta9 = params[8]\n",
    "  theta10 = params[9]\n",
    "  theta11 = params[10]\n",
    "  theta12 = params[11]\n",
    "\n",
    "  qcc.rx(x1, 0)\n",
    "  qcc.rx(x2, 1)\n",
    "  qcc.rzz(theta1, 0, 1)\n",
    "  qcc.ry(theta2, 0)\n",
    "  qcc.ry(theta3, 1)\n",
    "  qcc.rx(x1, 0)\n",
    "  qcc.rx(x2, 1)\n",
    "  qcc.rzz(theta4, 0, 1)\n",
    "  qcc.ry(theta5, 0)\n",
    "  qcc.ry(theta6, 1)\n",
    "  qcc.rx(x1, 0)\n",
    "  qcc.rx(x2, 1)\n",
    "  qcc.rzz(theta7, 0, 1)\n",
    "  qcc.ry(theta8, 0)\n",
    "  qcc.ry(theta9, 1)\n",
    "  qcc.rx(x1, 0)\n",
    "  qcc.rx(x2, 1)\n",
    "  qcc.rzz(theta10, 0, 1)\n",
    "  qcc.ry(theta11, 0)\n",
    "  qcc.ry(theta12, 1)\n",
    "  qcc.rx(x1, 0)\n",
    "  qcc.rx(x2, 1)\n",
    "\n",
    "  return qcc, inputs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator()\n",
    "\n",
    "def create_qnn():\n",
    "    \n",
    "    qcc, inputs, params = create_qcc(num_qubits, num_inputs, num_params)\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qcc,\n",
    "        input_params=inputs,\n",
    "        weight_params=params,\n",
    "        input_gradients=True,\n",
    "        estimator=estimator,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "qnn = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic neural network implementation\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)\n",
    "        self.fc2 = Linear(64, 2)  # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn) \n",
    "        self.fc3 = Linear(1, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet based implementation\n",
    "\n",
    "class ResNetQNN(nn.Module):\n",
    "    def __init__(self, qnn):\n",
    "        super(ResNetQNN, self).__init__()\n",
    "\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Modify input layer to accept grayscale images\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final FC layer\n",
    "        self.fc1 = nn.Linear(num_features, 2)  # reduce dim to 2: input to QNN\n",
    "\n",
    "        self.qnn = TorchConnector(qnn)  # quantum layer\n",
    "\n",
    "        # Final classification layer to output 2 logits for binary classification\n",
    "        self.fc2 = nn.Linear(1, 2)  # final classif layer \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.qnn(x) \n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x  # Return logits for 2 classes (0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one of the two models\n",
    "model = ResNetQNN(qnn)\n",
    "# model = Net(qnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "loss_func = CrossEntropyLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 20  \n",
    "loss_list = [] \n",
    "model.train() \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  \n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss convergence\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
